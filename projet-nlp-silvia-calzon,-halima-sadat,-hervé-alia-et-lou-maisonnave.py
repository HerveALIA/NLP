# -*- coding: utf-8 -*-
"""Projet_NLP_Silvia CALZON, Halima SADAT, Hervé ALIA et Lou_MAISONNAVE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L2w3b30W0mh9cvHxHcFs-lIUsmA4gmS7

# Projet NLP réalisé par Silvia CALZON, Halima SADAT, Hervé ALIA et Lou_MAISONNAVE

# 1- Librairies et Packages
"""

! pip install nltk

# Commented out IPython magic to ensure Python compatibility.
import numpy as np 
import pandas as pd 
import seaborn as sns
import matplotlib.pyplot as plt
from IPython.display import display
from sklearn.feature_extraction.text import TfidfVectorizer
import nltk
import re
import string
from nltk.tokenize import word_tokenize
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import warnings
warnings.simplefilter(action='ignore')

from nltk.stem import WordNetLemmatizer
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('words')
nltk.download('omw-1.4')

# %matplotlib inline

from nltk.stem import WordNetLemmatizer
import spacy
nlp = spacy.load("en_core_web_sm")
from scipy.cluster.hierarchy import linkage, fcluster
from scipy.spatial.distance import pdist

"""# 2- Chargement de mon fichier csv"""

data= pd.read_csv("/content/anthems.csv", encoding='utf-8')
data

### Récupération de mon df
df = data[['Continent', 'Anthem']]

df

"""# 3- Nettoyage des caractères spéciaux/ Stemming/ Lemmatization"""

### Fonction globale de nettoyage
def text_processing(texte):
    import re
    #sentence += " "
    cleaned=clean_text(texte)
    resultat = nett_caractere_spe(cleaned)
    resultat = remp_emoticon(resultat)
    resultat = remp_abreviation(resultat)
    resultat = supp_lettre_seule(resultat)
    resultat = re.sub('\n+', ' ', resultat.lower())
    resultat = re.sub(r'\d+', '', resultat)
    tokens = tokenize(resultat)
    #tokens = normalyse(cleaned)
    tokens = remove_stopwords(tokens)
    tokens = remove_Punctuation(tokens)
    tokens = lemmatize(tokens)
    return tokens
    
def clean_text(text):
    import re  #permet de traiter des donnees textuelles
    #https://docs.python.org/fr/3/library/re.html

    # lowers
    text = text.lower()
    # removes special chars
    text = re.sub(r'\W|_', ' ', text)
    # removes digits
    text = re.sub(r'[0-9]', '', text)
    # removes multiple spaces
    text = re.sub(r'\s+', ' ', text)
    # removes space at the start or end of the string
    text = re.sub(r'^\s|\s$', '', text)

    # remove all single characters
    text = re.sub(r'\s+[a-zA-Z]\s+', ' ', text)

    # Remove single characters from the start
    text = re.sub(r'\^[a-zA-Z]\s+', ' ', text)

    # Removing prefixed 'b'
    text = re.sub(r'^b\s+', ' ', text)
    
     # supprimer les liens
    text = re.sub(r'https?:\S+|http?:\S', ' link ', text)
    
    # Remplacer les mentions @XXX par ' user '
    text = re.sub(r"^@\S+|\s@\S+", ' user ', text)
    
    # Remplacer les #XXX par ' hashtags
    text = re.sub(r"^#\S+|\s#\S+", ' hashtag ', text)
    return text

def remp_emoticon(texte):  # Remplacer les emoticones par leur signification
    import re
    # mettre \ devant : ) ^
    # pas de \ devant : ; : - ] >
    resultat = re.sub(
        ';p|;P|:p|:P|xp|xP|=p|=P|:‑P|X‑P|x‑p|:‑p|:‑Þ|:‑þ|:‑b|>:P|d:|:b|:þ|:Þ',
        ' emoticon_langue ', texte)
    resultat = re.sub(':"D', 'emoticon_joyeux', resultat)
    resultat = re.sub(
        ":‑\)|:\)|:-]|:]|:->|:>|8-\)|8\)|:-}|:}|:o\)|:c\)|:\^\)|=]|=\)|:-\)\)|:'‑\)|:'\)",
        ' emoticon_joyeux ', resultat)
    resultat = re.sub(':‑D|:D|8‑D|8D|=D|=3|B\^D|c:|C:|x‑D|xD|X‑D|XD',
                      ' emoticon_rire ', resultat)
    resultat = re.sub(
        ":‑\(|:\(|:‑c|:c|:‑<|:<|:‑\[|:\[|>:\[|:{|:@|:\(|;\(|:'‑\(|:'\(|:=\(|v.v",
        ' emoticon_triste ', resultat)
    resultat = re.sub("D‑':|D:<|D:|D8|D;|D=|DX", ' emoticon_degout ', resultat)
    resultat = re.sub(
        ":‑O|:O|:‑o|:o|:-0|8‑0|>:O|=O|=o|=0|O_O|o_o|O-O|o‑o|O_o|o_O",
        ' emoticon_surprise ', resultat)
    resultat = re.sub(":-3|:3|=3|x3|X3|>:3", ' emoticon_chat ', resultat)
    resultat = re.sub(":-\|:\|:×|<3", ' emoticon_amour ', resultat)
    resultat = re.sub(";‑\)|;\)|\-\)|\\)|;‑]|;]|;\^\)|;>|:‑,|;D|;3|:‑J",
                      ' emoticon_clindoeil ', resultat)
    resultat = re.sub(":-/ |>.<|>_<|:/|:‑.|>:\|>:/|:\|=/|=\|:L|=L|:S",
                      ' emoticon_sceptique ', resultat)
    resultat = re.sub(
        "<<|>>|<.<|>.>|:$|://|://3|:‑X|:X|:‑#|:#|:‑&|:&|%‑\)|%\)",
        ' emoticon_embarrasse ', resultat)
    resultat = re.sub("8-X|8=X|x-3|x=3|X_X|x_x", ' emoticon_mort ', resultat)

    return resultat

def remp_abreviation(phrase):  # Remplacer les abréviations
    import re
    # specific
    phrase = phrase.lower()
    phrase = re.sub(r"won\'t", "will not", phrase)
    phrase = re.sub(r"can\'t", "can not", phrase)
    phrase = re.sub(r"cannot", "can not", phrase)
    phrase = re.sub(r"didnt", "did not", phrase)
    phrase = re.sub(r"couldnt", "could not", phrase)
    phrase = re.sub(r"doesnt", "does not", phrase)
    phrase = re.sub(r"dont", "do not", phrase)
    phrase = re.sub(r"hasnt", "has not", phrase)
    phrase = re.sub(r"hadnt", "had not", phrase)
    phrase = re.sub(r"havent", "have not", phrase)
    phrase = re.sub(r"ive", "i have", phrase)
    phrase = re.sub(r"im", "i am", phrase)
    phrase = re.sub(r"wasnt", "was not", phrase)
    phrase = re.sub(r"werent", "were not", phrase)
    phrase = re.sub(r"'cause", "because", phrase)
    phrase = re.sub(r"cos", "because", phrase)
    phrase = re.sub(r"f\*\*k", "fuck", phrase)
    phrase = re.sub(r"f\*\*king", "fucking", phrase)
    phrase = re.sub(r"idk", "i do not know", phrase)

    # general
    phrase = re.sub(r"n\'t", " not", phrase)
    phrase = re.sub(r"n\'", " not", phrase)
    phrase = re.sub(r"\'re", " are", phrase)
    phrase = re.sub(r"\'s", " is", phrase)
    phrase = re.sub(r"\'d", " would", phrase)
    phrase = re.sub(r"\'ll", " will", phrase)
    phrase = re.sub(r"\'t", " not", phrase)
    phrase = re.sub(r"\'ve", " have", phrase)
    phrase = re.sub(r"\'m", " am", phrase)
    phrase = re.sub(r" u ", " you ", phrase)
    phrase = re.sub(r" ur ", " your ", phrase)
    phrase = re.sub(r" n ", " and ", phrase)

    return phrase

def nett_caractere_spe(texte):
    import re
    resultat = re.sub('&gt;', '>', texte)
    resultat = re.sub('&lt;', '<', resultat)
    resultat = re.sub('&quot;', '\"', resultat)
    resultat = re.sub('&amp;', '&', resultat)
    return resultat

def supp_lettre_seule(
        texte
):  # supprime les lettres seules (les abbréviations type "u", "y r")
    resultat = " ".join(
        [v for v in texte.split(" ") if ((len(v) > 1) or (not v.isalpha()))])
    return resultat

"""
Tokenisation : séparation du texte en mots
"""
def tokenize(text):
    """La tokenization, qui désigne le découpage en mots des différents documents qui constituent votre corpus"""
    from nltk.tokenize import word_tokenize

    tokens= word_tokenize(text)
    return tokens

def remove_stopwords(tokens):
    import nltk
    stopwords = nltk.corpus.stopwords.words("english") 
    return [token for token in tokens if token not in stopwords]

def remove_Punctuation(tokens):
    import string
    return [t for t in tokens if t not in string.punctuation]

''''
La radicalisation utilise la racine du mot, tandis que la lemmatisation 
utilise le contexte dans lequel le mot est utilisé. 

Le stemming consiste à réduire un mot dans sa forme « racine ».
Le but du stemming est de regrouper de nombreuses variantes d’un mot comme un seul et même mot.
'''
from nltk.stem.snowball import SnowballStemmer
import nltk

# Text Stemming
def stem(tokens):
    return [nltk.PorterStemmer().stem(token) for token in tokens]

#Text Lemmatization
def lemmatize(tokens):
    return [nltk.WordNetLemmatizer().lemmatize(token) for token in tokens]

"""# 4- Vectorisation"""

def text_vectorization(data,col,size): #data=input data, col=colonne text, size=nombre de mots à considerer
    from sklearn.feature_extraction.text import TfidfVectorizer
    tfidf_vect = TfidfVectorizer(analyzer=text_processing,max_features=size)
    X = tfidf_vect.fit_transform(data[col])
    data_text = pd.DataFrame(X.toarray())
    data_text.columns = tfidf_vect.get_feature_names_out()  #names_out
    data[data_text.columns]=data_text
    data = data.drop(columns=col)
    return data

# all  #vectorization = regarder le nombre de fois ou le mot est sorti dans le paragraphe  et calcule sa freq
def preprocessing(data):
    #data=encodage_target_binary(data,col="Continent'")  #reequilibrage ## col : le nom de la target
    data=text_vectorization(data, "Anthem",size=15) ## Le nom de la colonne (features xi)
    return data

preprocessing(df)

df = preprocessing(df)

df

## 
# 1) Créer une matrice des variables indépendantes et le vecteur de la variable dépendante.
# X est la matrice et Y est le vecteur
# PS: Astuce : Très souvent la dernière colonne est la colonne dépendante le y à prédire
# La matrice des variables indépendantes est aussi appeelée matrice de featuresµ
X = df.drop('Continent', axis=1)  # Supprimer la colonne "target" de la matrice X
Y = df['Continent']              # Sélectionner uniquement la colonne "target" pour Y
X

Y

np.unique(Y)

"""# Standardisation des données """

from sklearn.preprocessing import StandardScaler

# Créer un objet StandardScaler
scaler = StandardScaler()
# Standardiser les données
X = scaler.fit_transform(X)

### Séparation du dataset en training_set et en test_set

from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 1/3, random_state= 0)

print(X_train)
print(X_test)
print(Y_train)
print(Y_test)

"""# MACHINE LEARNING SUPERVISE

# PARTIE A : MODELE DE CLASSIFICATION

## Modèle 1 : Regression logistique
"""

from sklearn.linear_model import LogisticRegression

# Créer et entraîner le modèle de régression logistique
model1 = LogisticRegression()
model1.fit(X_train, Y_train)

"""### Faire de nouvelles prédictions"""

Y_pred1 = model1.predict(X_test)
Y_pred1

print(Y_test)
print(Y_pred1)

"""## Matrice de confusion :

### La matrice de confusion est une représentation tabulaire utilisée pour évaluer les performances d'un modèle de classification. Elle permet de visualiser la qualité des prédictions du modèle en comparant les valeurs réelles des échantillons avec les prédictions effectuées par le modèle.
"""

from sklearn.metrics import confusion_matrix
CM1 = confusion_matrix(Y_test, Y_pred1)
CM1

# Étiquettes des classes
classes = ['Africa', 'Asia', 'Europe', 'North_America', 'Oceania', 'South_America']

# Créer une figure et un axe
fig, ax = plt.subplots()

# Afficher la matrice de confusion sous forme de heatmap
sns.heatmap(CM1, annot=True, fmt='d', xticklabels=classes, yticklabels=classes, cmap='Blues', ax=ax)

# Définir les labels des axes
ax.set_xlabel('Prédictions')
ax.set_ylabel('Vraies étiquettes')
ax.set_title('Matrice de confusion')

# Afficher la figure
plt.show()

from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, cohen_kappa_score, matthews_corrcoef

Accuracy_Rate1 = accuracy_score(Y_test, Y_pred1)
Error_rate1 = 1 - Accuracy_Rate1
F1_score1 = f1_score(Y_test, Y_pred1, average='weighted')  # Modifier le paramètre average ici
Precision1 = precision_score(Y_test, Y_pred1, average='weighted')  # Modifier le paramètre average ici
Recall1 = recall_score(Y_test, Y_pred1, average='weighted')  # Modifier le paramètre average ici
CK1 = cohen_kappa_score(Y_test, Y_pred1)
MC1 = matthews_corrcoef(Y_test, Y_pred1)

print("Precision : {:.2f}".format(Precision1))
print("Recall : {:.2f}".format(Recall1))
print("Accuracy Rate: ", Accuracy_Rate1)
print("Error rate: ", Error_rate1)
print("F1_score: ", F1_score1)
print("CK:", CK1)
print("MC:", MC1)

"""# Modèle 2 : SVM"""

from sklearn.svm import SVC

# Créer et entraîner le modèle SVM
model2 = SVC(kernel='rbf', C=1.0, gamma='scale')
model2.fit(X_train, Y_train)

# Faire des prédictions sur l'ensemble de test
Y_pred2 = model2.predict(X_test)
Y_pred2

print(Y_test)
print(Y_pred2)

from sklearn.metrics import confusion_matrix
CM2 = confusion_matrix(Y_test, Y_pred2)
CM2

# Étiquettes des classes
classes = ['Africa', 'Asia', 'Europe', 'North_America', 'Oceania', 'South_America']

# Créer une figure et un axe
fig, ax = plt.subplots()

# Afficher la matrice de confusion sous forme de heatmap
sns.heatmap(CM2, annot=True, fmt='d', xticklabels=classes, yticklabels=classes, cmap='Set2', ax=ax)

# Définir les labels des axes
ax.set_xlabel('Prédictions')
ax.set_ylabel('Vraies étiquettes')
ax.set_title('Matrice de confusion')

# Afficher la figure
plt.show()

Accuracy_Rate2 = accuracy_score(Y_test, Y_pred2)
Error_rate2 = 1 - Accuracy_Rate2
F1_score2 = f1_score(Y_test, Y_pred2, average='weighted')  # Modifier le paramètre average ici
Precision2 = precision_score(Y_test, Y_pred2, average='weighted')  # Modifier le paramètre average ici
Recall2 = recall_score(Y_test, Y_pred2, average='weighted')  # Modifier le paramètre average ici
CK2 = cohen_kappa_score(Y_test, Y_pred2)
MC2 = matthews_corrcoef(Y_test, Y_pred2)

print("Precision : {:.2f}".format(Precision2))
print("Recall : {:.2f}".format(Recall2))
print("Accuracy Rate: ", Accuracy_Rate2)
print("Error rate: ", Error_rate2)
print("F1_score: ", F1_score2)
print("CK:", CK2)
print("MC:", MC2)

"""# Modèle 3 : Naive Bayes"""

from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Créer et entraîner le modèle Naive Bayes
model3 = GaussianNB()
model3.fit(X_train, Y_train)

# Faire des prédictions sur l'ensemble de test
Y_pred3 = model3.predict(X_test)
Y_pred3

from sklearn.metrics import confusion_matrix
CM3 = confusion_matrix(Y_test, Y_pred3)
CM3

# Étiquettes des classes
classes = ['Africa', 'Asia', 'Europe', 'North_America', 'Oceania', 'South_America']

# Créer une figure et un axe
fig, ax = plt.subplots()

# Afficher la matrice de confusion sous forme de heatmap
sns.heatmap(CM3, annot=True, fmt='d', xticklabels=classes, yticklabels=classes, cmap='Accent', ax=ax)

# Définir les labels des axes
ax.set_xlabel('Prédictions')
ax.set_ylabel('Vraies étiquettes')
ax.set_title('Matrice de confusion')

# Afficher la figure
plt.show()

Accuracy_Rate3 = accuracy_score(Y_test, Y_pred3)
Error_rate3 = 1 - Accuracy_Rate3
F1_score3 = f1_score(Y_test, Y_pred3, average='weighted')  # Modifier le paramètre average ici
Precision3 = precision_score(Y_test, Y_pred3, average='weighted')  # Modifier le paramètre average ici
Recall3 = recall_score(Y_test, Y_pred3, average='weighted')  # Modifier le paramètre average ici
CK3 = cohen_kappa_score(Y_test, Y_pred3)
MC3 = matthews_corrcoef(Y_test, Y_pred3)

print("Precision : {:.2f}".format(Precision3))
print("Recall : {:.2f}".format(Recall3))
print("Accuracy Rate: ", Accuracy_Rate3)
print("Error rate: ", Error_rate3)
print("F1_score: ", F1_score3)
print("CK:", CK3)
print("MC:", MC3)

"""# Modèle 4 : Arbre de décision """

from sklearn.tree import DecisionTreeClassifier

# Créer et entraîner le modèle d'arbre de décision
model4 = DecisionTreeClassifier()
model4.fit(X_train, Y_train)

# Faire des prédictions sur l'ensemble de test
Y_pred4 = model4.predict(X_test)
Y_pred4

CM4 = confusion_matrix(Y_test, Y_pred4)
CM4

# Étiquettes des classes
classes = ['Africa', 'Asia', 'Europe', 'North_America', 'Oceania', 'South_America']

# Créer une figure et un axe
fig, ax = plt.subplots()

# Afficher la matrice de confusion sous forme de heatmap
sns.heatmap(CM4, annot=True, fmt='d', xticklabels=classes, yticklabels=classes, cmap='Pastel2', ax=ax)

# Définir les labels des axes
ax.set_xlabel('Prédictions')
ax.set_ylabel('Vraies étiquettes')
ax.set_title('Matrice de confusion')

# Afficher la figure
plt.show()

Accuracy_Rate4 = accuracy_score(Y_test, Y_pred4)
Error_rate4 = 1 - Accuracy_Rate4
F1_score4 = f1_score(Y_test, Y_pred4, average='weighted')  # Modifier le paramètre average ici
Precision4 = precision_score(Y_test, Y_pred4, average='weighted')  # Modifier le paramètre average ici
Recall4 = recall_score(Y_test, Y_pred4, average='weighted')  # Modifier le paramètre average ici
CK4 = cohen_kappa_score(Y_test, Y_pred4)
MC4 = matthews_corrcoef(Y_test, Y_pred4)

print("Precision : {:.2f}".format(Precision4))
print("Recall : {:.2f}".format(Recall4))
print("Accuracy Rate: ", Accuracy_Rate4)
print("Error rate: ", Error_rate4)
print("F1_score: ", F1_score4)
print("CK:", CK4)
print("MC:", MC4)

"""# Modèle 5 : Random Forest"""

from sklearn.ensemble import RandomForestClassifier

# Créer et entraîner le modèle Random Forest
model5 = RandomForestClassifier(n_estimators=100)
model5.fit(X_train, Y_train)

# Faire des prédictions sur l'ensemble de test
Y_pred5 = model5.predict(X_test)
Y_pred5

CM5 = confusion_matrix(Y_test, Y_pred5)
CM5

# Étiquettes des classes
classes = ['Africa', 'Asia', 'Europe', 'North_America', 'Oceania', 'South_America']

# Créer une figure et un axe
fig, ax = plt.subplots()

# Afficher la matrice de confusion sous forme de heatmap
sns.heatmap(CM5, annot=True, fmt='d', xticklabels=classes, yticklabels=classes, cmap='tab20c', ax=ax)

# Définir les labels des axes
ax.set_xlabel('Prédictions')
ax.set_ylabel('Vraies étiquettes')
ax.set_title('Matrice de confusion')

# Afficher la figure
plt.show()

Accuracy_Rate5 = accuracy_score(Y_test, Y_pred5)
Error_rate5 = 1 - Accuracy_Rate5
F1_score5 = f1_score(Y_test, Y_pred5, average='weighted')  # Modifier le paramètre average ici
Precision5 = precision_score(Y_test, Y_pred5, average='weighted')  # Modifier le paramètre average ici
Recall5 = recall_score(Y_test, Y_pred5, average='weighted')  # Modifier le paramètre average ici
CK5 = cohen_kappa_score(Y_test, Y_pred5)
MC5 = matthews_corrcoef(Y_test, Y_pred5)

print("Precision : {:.2f}".format(Precision5))
print("Recall : {:.2f}".format(Recall5))
print("Accuracy Rate: ", Accuracy_Rate5)
print("Error rate: ", Error_rate5)
print("F1_score: ", F1_score5)
print("CK:", CK5)
print("MC:", MC5)

"""# Modèle 6 : Gradient Boosting"""

from sklearn.ensemble import GradientBoostingClassifier

# Créer et entraîner le modèle Gradient Boosting
model6 = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)
model6.fit(X_train, Y_train)

# Faire des prédictions sur l'ensemble de test
Y_pred6 = model6.predict(X_test)
Y_pred6

CM6 = confusion_matrix(Y_test, Y_pred6)
CM6

# Étiquettes des classes
classes = ['Africa', 'Asia', 'Europe', 'North_America', 'Oceania', 'South_America']

# Créer une figure et un axe
fig, ax = plt.subplots()

# Afficher la matrice de confusion sous forme de heatmap
sns.heatmap(CM6, annot=True, fmt='d', xticklabels=classes, yticklabels=classes, cmap='gnuplot2', ax=ax)

# Définir les labels des axes
ax.set_xlabel('Prédictions')
ax.set_ylabel('Vraies étiquettes')
ax.set_title('Matrice de confusion')

# Afficher la figure
plt.show()

Accuracy_Rate6 = accuracy_score(Y_test, Y_pred6)
Error_rate6 = 1 - Accuracy_Rate6
F1_score6 = f1_score(Y_test, Y_pred6, average='weighted')  # Modifier le paramètre average ici
Precision6 = precision_score(Y_test, Y_pred6, average='weighted')  # Modifier le paramètre average ici
Recall6 = recall_score(Y_test, Y_pred6, average='weighted')  # Modifier le paramètre average ici
CK6 = cohen_kappa_score(Y_test, Y_pred6)
MC6 = matthews_corrcoef(Y_test, Y_pred6)

print("Precision : {:.2f}".format(Precision6))
print("Recall : {:.2f}".format(Recall6))
print("Accuracy Rate: ", Accuracy_Rate6)
print("Error rate: ", Error_rate6)
print("F1_score: ", F1_score6)
print("CK:", CK6)
print("MC:", MC6)

# Données de performance pour chaque modèle

model_data = {
    'RL': {
        'Precision': Precision1,
        'Recall': Recall1,
        'Accuracy Rate': Accuracy_Rate1,
        'Error rate': Error_rate1,
        'F1_score': F1_score1,
        'CK': CK1,
        'MC': MC1,
    },
    'SVM': {
        'Precision': Precision2,
        'Recall': Recall2,
        'Accuracy Rate': Accuracy_Rate2,
        'Error rate': Error_rate2,
        'F1_score': F1_score2,
        'CK': CK2,
        'MC': MC2,
    },
    'NB': {
        'Precision': Precision3,
        'Recall': Recall3,
        'Accuracy Rate': Accuracy_Rate3,
        'Error rate': Error_rate3,
        'F1_score': F1_score3,
        'CK': CK3,
        'MC': MC3,
    },
    'AD': {
        'Precision': Precision4,
        'Recall': Recall4,
        'Accuracy Rate': Accuracy_Rate4,
        'Error rate': Error_rate4,
        'F1_score': F1_score4,
        'CK': CK4,
        'MC': MC4,
    },
    'RDF': {
        'Precision': Precision5,
        'Recall': Recall5,
        'Accuracy Rate': Accuracy_Rate5,
        'Error rate': Error_rate5,
        'F1_score': F1_score5,
        'CK': CK5,
        'MC': MC5,
    },
    'GB': {
        'Precision': Precision6,
        'Recall': Recall6,
        'Accuracy Rate': Accuracy_Rate6,
        'Error rate': Error_rate6,
        'F1_score': F1_score6,
        'CK': CK6,
        'MC': MC6,
    }
}

# Créer un DataFrame pour chaque métrique de performance
precision_df = pd.DataFrame.from_dict({k: v['Precision'] for k, v in model_data.items()}, orient='index')
recall_df = pd.DataFrame.from_dict({k: v['Recall'] for k, v in model_data.items()}, orient='index')
accuracy_df = pd.DataFrame.from_dict({k: v['Accuracy Rate'] for k, v in model_data.items()}, orient='index')
error_df = pd.DataFrame.from_dict({k: v['Error rate'] for k, v in model_data.items()}, orient='index')
f1_score_df = pd.DataFrame.from_dict({k: v['F1_score'] for k, v in model_data.items()}, orient='index')
CK_df = pd.DataFrame.from_dict({k: v['CK'] for k, v in model_data.items()}, orient='index')
MC_df = pd.DataFrame.from_dict({k: v['MC'] for k, v in model_data.items()}, orient='index')

# Placer tous les tableaux dans une liste pour les concaténer horizontalement
dfs = [precision_df, recall_df, accuracy_df, error_df, f1_score_df, CK_df, MC_df]

# Concaténer horizontalement les tableaux pour créer un seul DataFrame
results_df = pd.concat(dfs, axis=1)

# Renommer les colonnes pour qu'elles correspondent aux métriques de performance
results_df.columns = ['Precision', 'Recall', 'Accuracy Rate', 'Error rate', 'F1_score', 'CK', 'MC']

# Tracer les performances de chaque modèle pour chaque métrique
results_df.plot(kind='bar', figsize=(15, 7))
plt.title('Comparaison des modèles')
plt.ylabel('Score')
plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))
plt.show()

"""# PARTIE B : Partitionnement en k moyennes :"""

df = pd.read_excel("/content/anthems.xlsx")
df.drop('Unnamed: 0', axis=1, inplace=True)
df

corpus = df['Anthem'].tolist()
corpus[18][0:447]

vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(corpus)
tf_idf = pd.DataFrame(data = X.toarray(), columns=vectorizer.get_feature_names_out())

final_df = tf_idf

print("{} rows".format(final_df.shape[0]))
final_df.T.nlargest(100, 0)

"""**K-MEANS**

Fonction qui exécute l’algorithme K-Means max_k fois et retourne un dictionnaire de chaque résultat k
"""

def run_KMeans(max_k, df):
    max_k += 1
    kmeans_results = dict()
    for k in range(2 , max_k):
        kmeans = cluster.KMeans(n_clusters = k
                               , init = 'k-means++'
                               , n_init = 10
                               , tol = 0.0001
                               , random_state = 1
                               , algorithm = 'full')

        kmeans_results.update( {k : kmeans.fit(df)} )
        
    return kmeans_results

"""# Silhouette Score de notre variable Anthem

Silhouette Score C'est une mesure de la similitude d’un objet avec son propre cluster (cohésion) par rapport à d’autres clusters (séparation).
"""

# K-Means
from sklearn import cluster
def printAvg(avg_dict):
    for avg in sorted(avg_dict.keys(), reverse=True):
        print("Avg: {}\tK:{}".format(avg.round(4), avg_dict[avg]))
        
def plotSilhouette(df, n_clusters, kmeans_labels, silhouette_avg):
    fig, ax1 = plt.subplots(1)
    fig.set_size_inches(8, 6)
    ax1.set_xlim([-0.2, 1])
    ax1.set_ylim([0, len(df) + (n_clusters + 1) * 20])
    
    ax1.axvline(x=silhouette_avg, color="red", linestyle="--") # The vertical line for average silhouette score of all the values
    ax1.set_yticks([])  # Clear the yaxis labels / ticks
    ax1.set_xticks([-0.2, 0, 0.2, 0.4, 0.6, 0.8, 1])
    plt.title(("Silhouette analysis for K = %d" % n_clusters), fontsize=10, fontweight='bold')
    
    y_lower = 10
    sample_silhouette_values = silhouette_samples(df, kmeans_labels) # Compute the silhouette scores for each sample
    for i in range(n_clusters):
        ith_cluster_silhouette_values = sample_silhouette_values[kmeans_labels == i]
        ith_cluster_silhouette_values.sort()

        size_cluster_i = ith_cluster_silhouette_values.shape[0]
        y_upper = y_lower + size_cluster_i

        color = cm.nipy_spectral(float(i) / n_clusters)
        ax1.fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_silhouette_values, facecolor=color, edgecolor=color, alpha=0.7)

        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i)) # Label the silhouette plots with their cluster numbers at the middle
        y_lower = y_upper + 10  # Compute the new y_lower for next plot. 10 for the 0 samples
    plt.show()
    
        
def silhouette(kmeans_dict, df, plot=False):
    df = df.to_numpy()
    avg_dict = dict()
    for n_clusters, kmeans in kmeans_dict.items():      
        kmeans_labels = kmeans.predict(df)
        silhouette_avg = silhouette_score(df, kmeans_labels) # Average Score for all Samples
        avg_dict.update( {silhouette_avg : n_clusters} )
    
        if(plot): plotSilhouette(df, n_clusters, kmeans_labels, silhouette_avg)
        
def get_silhouette_scores(data, max_k):
    scores = []
    
    for k in range(2, max_k+1):
        kmeans = KMeans(n_clusters=k, random_state=0).fit(data)
        score = silhouette_score(data, kmeans.labels_)
        scores.append(score)
    
    return scores

max_k = 20
df4_array = final_df.values
scores = get_silhouette_scores(df4_array, max_k)

plt.figure(figsize=(10,5))

plt.plot(range(2, max_k+1), scores)

plt.title("Silhouette du score de chaque k")
plt.xlabel("Nombre de clusters")
plt.ylabel("Silhouette du score")

plt.show()

n_clusters = np.argmax(scores) + 10  # Nombre optimal de clusters
kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(df4_array)
labels = kmeans.labels_
final_df['Cluster'] = labels

from sklearn.metrics                  import silhouette_samples, silhouette_score
import matplotlib.cm      as cm
# Running Kmeans
k = 10
kmeans_results = run_KMeans(k, final_df)

# Plotting Silhouette Analysis
silhouette(kmeans_results, final_df, plot=True)

"""Le score de silhouette offre une représentation plus riche que la courbe coudée.

Sur ce graphique, les barres verticales en rouge et en pointillé représentent le score de silhouette global pour chaque k choisi. On voit par exemple que pour tous les k représentés ici, le score de silhouette est trés faible elle est entre 0,4 et 0,6, et varie peu. Ensuite, pour un k donné, on va avoir la représentation des scores de silhouette de chaque observation, regroupées par cluster. Par exemple, pour k = 10, ici, on voit bien dix couleurs différentes qui sont les 10 clusters modélisés.

Les ordonnées sont toutes les observations clusterisées et en abscisses on a le score de silhouette de chaque observation. Si au sein d’un cluster, les observations ont un score de silhouette plus faible que le score de silhouette global (ligne verticale en rouge), cela signifie que les observations du clusters sont trop proches des autres clusters.

Enfin, quand le score de silhouette est négatif, cela signifie que la moyenne des distances de l’observation aux observations du cluster le plus proche est inférieure à la moyenne des distances de l’observation aux observations de son cluster. Cela signifie que l’observation est mal classée.

# Ajouter au dataset original une variable “cluster“ indiquant pour chaque observation le cluster auquel elle appartient.
"""

def get_top_features_cluster(tf_idf_array, prediction, n_feats):
    labels = np.unique(prediction)
    dfs = []
    for label in labels:
        id_temp = np.where(prediction == label)  # indices for each cluster
        x_means = np.mean(tf_idf_array[id_temp], axis=0)  # returns average score across cluster
        sorted_means = np.argsort(x_means)[::-1][:n_feats]  # indices with top n_feats scores
        features = vectorizer.get_feature_names_out()
        best_features = [(features[i], x_means[i]) for i in sorted_means if i < len(features)]
        df = pd.DataFrame(best_features, columns=['features', 'score'])
        dfs.append(df)
    return dfs




def plotWords(dfs, n_feats):
    plt.figure(figsize=(8, 4))
    for i in range(0, len(dfs)):
        plt.title(("Most Common Words in Cluster {}".format(i)), fontsize=10, fontweight='bold')
        sns.barplot(x = 'score' , y = 'features', orient = 'h' , data = dfs[i][:n_feats])
        plt.show()

best_result = 5
kmeans = kmeans_results.get(best_result)

final_df_array = final_df.to_numpy()

prediction = kmeans.predict(final_df)
n_feats = 20
dfs = get_top_features_cluster(final_df_array, prediction, n_feats)
plotWords(dfs, 13)

"""# Identification des mots significatifs dans chaque cluster"""

final_df['Cluster'] = labels

for i in range(n_clusters):
    print(f"\nCluster {i}:")
    cluster_hymne = final_df[final_df['Cluster']==i]

    cluster_words = final_df.loc[final_df['Cluster']==i].drop(columns=['Cluster']).sum().sort_values(ascending=False)
    print(f"\nMots les plus fréquents par cluster {i}:")
    print(cluster_words[:10])

"""# Diminution des dimensions pour visualiser les clusters"""

features = final_df.drop(columns=['Cluster']).values

pca = PCA(n_components=2)
features_pca = pca.fit_transform(features)

clusters = final_df['Cluster'].values

df_visualize = pd.DataFrame(data=features_pca, columns=['PC1', 'PC2'])
df_visualize['Cluster'] = clusters

num_clusters = len(df_visualize['Cluster'].unique())

colors = cm.get_cmap('tab10', num_clusters)

plt.figure(figsize=(12, 12))

for cluster in df_visualize['Cluster'].unique():
    df_cluster = df_visualize[df_visualize['Cluster'] == cluster]
    plt.scatter(df_cluster['PC1'], df_cluster['PC2'], color=colors(cluster), label=f'Cluster {cluster}')

plt.xlabel('PC1')
plt.ylabel('PC2')
plt.title('Visualisation des clusters')
plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=1, mode='expand')

plt.show()

distance_matrix = pdist(df_visualize[['PC1', 'PC2']], metric='euclidean') #Matrice des distances de type euclidienne

linkage_matrix = linkage(distance_matrix, method='average') #Regroupement hiérarchique
clusters = fcluster(linkage_matrix, t=10, criterion='maxclust') #définition du nombre de cluster dans chaque regroupement

df_visualize['Merged_Cluster'] = clusters
color_map = plt.get_cmap('tab10')
merged_cluster_labels = df_visualize['Merged_Cluster'].unique()

plt.figure(figsize=(10,6))

for merged_cluster in merged_cluster_labels:
    df_merged_cluster = df_visualize[df_visualize['Merged_Cluster'] == merged_cluster]
    plt.scatter(df_merged_cluster['PC1'], df_merged_cluster['PC2'], color=color_map(merged_cluster), label=f'Merged Cluster {merged_cluster}')

plt.xlabel('PC1')
plt.ylabel('PC2')
plt.title('Clusters fusionnés')

plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=1, mode='expand')

plt.show()

"""# Représenter les mots les plus fréquents dans chaque cluster avec un nuage de mots."""

# Transforms a centroids dataframe into a dictionary to be used on a WordCloud.
def centroidsDict(centroids, index):
    a = centroids.T[index].sort_values(ascending = False).reset_index().values
    centroid_dict = dict()

    for i in range(0, len(a)):
        centroid_dict.update( {a[i,0] : a[i,1]} )

    return centroid_dict

def generateWordClouds(centroids):
    wordcloud = WordCloud(max_font_size=100, background_color = 'white')
    for i in range(0, len(centroids)):
        centroid_dict = centroidsDict(centroids, i)        
        wordcloud.generate_from_frequencies(centroid_dict)

        plt.figure()
        plt.title('Cluster {}'.format(i))
        plt.imshow(wordcloud)
        plt.axis("off")
        plt.show()

from wordcloud    import WordCloud

# Créer le DataFrame centroids à partir des centroïdes
centroids = pd.DataFrame(kmeans.cluster_centers_, columns=final_df.columns)

# Générer les nuages de mots
generateWordClouds(centroids)

"""# Représenter les pays dans le plan engendré par les deux premières composantes principale avec une couleur par cluster."""

# Assigning the cluster labels to each country
labels = kmeans.labels_ 
data['label'] = labels
data

pip install geopandas

# Map Viz
import json
import geopandas as gpd
import json
# Loading countries polygons
geo_path = '/content/world-countries.json'
country_geo = json.load(open(geo_path))
gpf = gpd.read_file(geo_path)

# Merging on the alpha-3 country codes
merge = pd.merge(gpf, data, left_on='id', right_on='Alpha-3')
data_to_plot = merge[["id", "name", "label", "geometry"]]

data_to_plot

import branca.colormap as cm

# Creating a discrete color map
values = data_to_plot[['label']].to_numpy()
color_step = cm.StepColormap(['r', 'y','g','b', 'm'], vmin=values.min(), vmax=values.max(), caption='step')
color_step

"""# Représenter les pays sur une carte géographique avec une couleur par cluster."""

import folium
from branca.element import Figure

def make_geojson_choropleth(display, data, colors):
    '''creates geojson choropleth map using a colormap, with tooltip for country names and groups'''
    group_dict = data.set_index('id')['label'] # Dictionary of Countries IDs and Clusters
    tooltip = folium.features.GeoJsonTooltip(["name", "label"], aliases=display, labels=True)
    return folium.GeoJson(data[["id", "name","label","geometry"]],
                          style_function = lambda feature: {
                               'fillColor': colors(group_dict[feature['properties']['id']]),
                               #'fillColor': test(feature),
                               'color':'black',
                               'weight':0.5
                               },
                          highlight_function = lambda x: {'weight':2, 'color':'black'},
                          smooth_factor=2.0,
                          tooltip = tooltip)

# Makes map appear inline on notebook
def display(m, width, height):
    """Takes a folium instance and embed HTML."""
    fig = Figure(width=width, height=height)
    fig.add_child(m)
    return fig

# Initializing our Folium Map
m = folium.Map(location=[43.5775, -10.106111], zoom_start=2.3, tiles='cartodbpositron')

# Making a choropleth map with geojson
geojson_choropleth = make_geojson_choropleth(["Country:", "Cluster:"], data_to_plot, color_step)
geojson_choropleth.add_to(m)

width, height = 1300, 675
display(m, width, height)
m

"""# Partitionnement hiérarchique : Mêmes questions que ci-dessus. Tracer un dendrogramme."""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from scipy.cluster.hierarchy import dendrogram, linkage, fcluster
from wordcloud import WordCloud

# Perform hierarchical clustering
Z = linkage(final_df, method='average', metric='euclidean')

# Set the threshold to obtain clusters
threshold = 1.0
clusters = fcluster(Z, threshold, criterion='distance')

# Compute TF-IDF matrix
vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(final_df)

# Get top features (words) for each cluster
def get_top_features_cluster(tfidf_matrix, prediction, n_feats):
    labels = np.unique(prediction)
    dfs = []
    for label in labels:
        id_temp = np.where(prediction == label)
        x_means = np.mean(tfidf_matrix[id_temp], axis=0).A1
        sorted_means = np.argsort(x_means)[::-1][:n_feats]
        features = vectorizer.get_feature_names_out()
        best_features = [(features[i], x_means[i]) for i in sorted_means]
        df = pd.DataFrame(best_features, columns=['features', 'score'])
        dfs.append(df)
    return dfs

# Generate dendrogram
plt.figure(figsize=(10, 6))
dendrogram(Z, leaf_rotation=900., leaf_font_size=8.)
plt.title("Dendrogram")
plt.xlabel("Indices des échantillons")
plt.ylabel("Distance")
plt.show()

# Select the clusters to display
selected_clusters = [0, 2, 4]  # Adjust the cluster indices as per your requirement

# Get top features for selected clusters
n_feats = 10
dfs = get_top_features_cluster(tfidf_matrix, clusters, n_feats)

# Generate word clouds for selected clusters
for i in selected_clusters:
    centroid_dict = dict(zip(dfs[i]['features'], dfs[i]['score']))
    wordcloud = WordCloud(max_font_size=100, background_color='white')
    wordcloud.generate_from_frequencies(centroid_dict)
    
    plt.figure()
    plt.title('Cluster {}'.format(i))
    plt.imshow(wordcloud)
    plt.axis("off")
    plt.show()