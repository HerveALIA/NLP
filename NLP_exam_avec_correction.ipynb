{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvSblQSUMc_L"
      },
      "source": [
        "# Examen NLP avec python 2023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McvC1CR5MinT"
      },
      "source": [
        "### Sujet\n",
        "\n",
        "L'objectif de cet examen est d'analyser un corpus de textes et de le catégoriser par thématique. \n",
        "\n",
        "Le corpus est 20 newsgroup. Il est composé de posts de média répartis en 20 catégories différentes. \n",
        "Les données sont labellisées. \n",
        "\n",
        "Vous allez utiliser une approche supervisée et une approche non supervisée pour cette tâche. \n",
        "\n",
        "Pour la partie supervisée, vous allez utiliser un algorithme de classification de texte. Les labels fournis permettront d'apprendre à catégoriser les posts en fonction de leur thématique.\n",
        "\n",
        "Pour la partie non-supervisée, vous allez utiliser une technique de topic modeling pour découvrir des catégories (clusters) parmi les données sans utiliser les labels fournis. Vous utiliserez uniquement le nombre de catégories existantes, qui sera le nombre de clusters que vous cherchez. \n",
        "\n",
        "Chacune des techniques nécessitera une étape de vectorisation et sera évaluée avec une métrique adaptée. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiFg74ITZuVz"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Fp3T5zdMx64"
      },
      "source": [
        "### Consignes\n",
        "\n",
        "Le fichier peut être exécuté au choix sur Colab, Kaggle ou sur votre envrionnement local. Colab et Kaggle sont fortement conseillés pour limiter les problèmes liés à l'installation de librairies. De plus, Le GPU peut être utilisé sur Kaggle pour limiter les temps de calcul (surtout pour l'utilisation de grands modèles).\n",
        "\n",
        "Toutes les cellules comprenant l'emoji ➡️ sont des consignes avec différentes tâches à réaliser. \n",
        "\n",
        "Les cellules vides doivent être complétées. Vous pouvez ajouter autant de cellules que vous le souhaitez.\n",
        "\n",
        "Vous n'êtes pas obligé·e·s de faire l'examen dans l'ordre. Cependant il doit être rendu dans l'ordre fourni au début et il sera exécuté dans cet ordre pour la correction. \n",
        "\n",
        "Attention à la mémoire tampon des notebooks. Si vous rencontrer des problèmes pendant l'examen, pensez à redémarrer l'environnement d'exécution. De même, il est conseillé d'essayer de redémarrer l'environnement d'exécution et de relancer le code avant de rendre le devoir pour vérifier que tout fonctionne.\n",
        "\n",
        "Il est vivement recommandé d'utiliser les librairies existantes pour réaliser les différentes tâches demandées. Cependant, tous les choix de paramètres doivent être motivés. Si des paramètres inutiles ou non expliqués sont présents dans le code, cela sera pris en compte dans la notation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQN-2oYVZxNa"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐ Barème pour les intervenant·e·s : \n",
        "\n",
        "Le barème est proposé pour une note sur 20. \n",
        "\n",
        "Il est pûrement indicatif afin d'harmoniser le traitement des travaux entre les campus. \n",
        "\n",
        "Une partie des points peut être donnée si les choix d'implémentation sont bons mais que le code plante. \n",
        "De même, une partie des points peut être retirée si le code tourne mais qu'il n'est pas propre, que les noms de variables ne sont pas explicites, que des lignes sont dupliquées ou inutiles, etc...\n",
        "\n"
      ],
      "metadata": {
        "id": "MkRt_5aH8KPC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhSgL41pMzpj"
      },
      "source": [
        "## Import des packages"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "➡️ Ajouter les packages nécessaires au fur et à mesure de l'examen."
      ],
      "metadata": {
        "id": "dKtqMgzB1elK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ltHYIh7M1tM"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4dFBdN2NGgN"
      },
      "source": [
        "## Etude des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cgs42_ZBNR8H"
      },
      "source": [
        "### Chargement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYn3Yx0kQmIp"
      },
      "source": [
        "➡️ Exécuter le code suivant pour charger les données."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwlQyrAPNYfK"
      },
      "outputs": [],
      "source": [
        "news_dataset = fetch_20newsgroups(subset='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoNQ9WmFNUjr"
      },
      "source": [
        "### Caractéristiques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkNE01QBX4DS"
      },
      "source": [
        "➡️ Afficher la taille du dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMtn49qWX75J"
      },
      "outputs": [],
      "source": [
        "# correction\n",
        "print(f\"Taille du dataset : {len(news_dataset.data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐ Barème : 1 point"
      ],
      "metadata": {
        "id": "omH0k0sW9w83"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpGOKzjUYiaz"
      },
      "source": [
        "➡️ Afficher le nom des catégories du dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qigyz3gPYhSJ"
      },
      "outputs": [],
      "source": [
        "# correction\n",
        "news_dataset.target_names"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐ Barème : 1 point"
      ],
      "metadata": {
        "id": "cAPB0v3R93AD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_sd79VMOTJZ"
      },
      "source": [
        "## Vectorisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f1ECAsXN33Y"
      },
      "source": [
        "➡️ Séparer les données en un jeu d'entraînement et un jeu de test en réduisant le jeu d'entraînement à 1000 exemples et le jeu de test à 250 exemples pour limiter les temps de calcul.\n",
        "\n",
        "Attentions à répartir équitablement les classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNPNgN4IN_Ui"
      },
      "outputs": [],
      "source": [
        "# correction sklearn train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_news, x_test_news, y_train_news, y_test_news = train_test_split(news_dataset.data, news_dataset.target, train_size=1000, test_size=250, shuffle=True, stratify=news_dataset.target)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐ Barème : 3 points\n",
        "\n",
        "- découpage et nommage des variables (1 point)\n",
        "- respect des proportions (1 point)\n",
        "- utilisation de `stratify` (1 point)"
      ],
      "metadata": {
        "id": "nN6EcyLK98Ir"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FH72QM2FQXO6"
      },
      "source": [
        "➡️ Choisir une méthode de vectorisation adaptée à la tâche à réaliser. \n",
        "\n",
        "➡️ Implémenter cette méthode et vectoriser l'ensemble des données.\n",
        "\n",
        "➡️ Justifier le choix de la méthode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGPUa1JbOYca"
      },
      "outputs": [],
      "source": [
        "# correction BOW\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "bow_vectorizer = CountVectorizer()\n",
        "X_train_bow = bow_vectorizer.fit_transform(X_train_news)\n",
        "x_test_bow = bow_vectorizer.transform(x_test_news)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6SIaqLjbm2c"
      },
      "outputs": [],
      "source": [
        "# correction TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_news)\n",
        "x_test_tfidf = tfidf_vectorizer.transform(x_test_news)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fvAKAGwfR-W"
      },
      "outputs": [],
      "source": [
        "# correction Bert\n",
        "! pip install transformers\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "last_hidden_state_index = 0\n",
        "batch_index = 0\n",
        "cls_token_index = 0\n",
        "\n",
        "def encode_text(text):\n",
        "  encoded_input = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
        "  output = model(**encoded_input)\n",
        "  cls_token = output[last_hidden_state_index][batch_index][cls_token_index].tolist()\n",
        "  return cls_token\n",
        "\n",
        "X_train_bert = []\n",
        "for utterance in X_train_news:\n",
        "  X_train_bert.append(encode_text(utterance))\n",
        "\n",
        "x_test_bert = []\n",
        "for utterance in x_test_news:\n",
        "  x_test_bert.append(encode_text(utterance))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐ Barème : 5 points \n",
        "\n",
        "- choix de la méthode adaptée (1 point)\n",
        "- justification pertinente (1 point)\n",
        "- pour BOW ou TF-IDF :\n",
        "  - instanciation du modèle sans paramètre inutile (1 point)\n",
        "  - utilisation de la méthode `fit_transform` sur les données d'entraînement (1 point)\n",
        "  - utilisation de la méthode `transform` sur les données de test (1 point)\n",
        "- pour les méthodes de type embeddings contextualisés, Bert et autres :\n",
        "  - choix du modèle pertinent (1 point)\n",
        "  - technique de vectorisation (1 point)\n",
        "  - utilisation du token cls ou autre à justifier (1 point)\n",
        "- à adapter pour toute autre méthode de vectorisation"
      ],
      "metadata": {
        "id": "eIxjQ0E2A_9I"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FTYiTjgNeOZ"
      },
      "source": [
        "## Classification supervisée"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nadwtE0vN_qz"
      },
      "source": [
        "➡️ Choisir un algorithme vous paraissant pertinent pour la tâche de catégorisation de texte.\n",
        "\n",
        "➡️ Entraîner le modèle grâce au jeu d'entraînement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnwdgorPNghQ"
      },
      "outputs": [],
      "source": [
        "# correction\n",
        "from sklearn import svm\n",
        "\n",
        "classif_model_tfidf = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto',probability=True)    \n",
        "classif_model_tfidf.fit(X_train_tfidf,y_train_news)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐ Barème 3 points: \n",
        "\n",
        "- choix du modèle de classification pertinent (1 point)\n",
        "- utilisation de la méthode `fit` sur les données d'entraînement (2 points)"
      ],
      "metadata": {
        "id": "UoLFOE27C1V5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tazjeDYjOMPU"
      },
      "source": [
        "➡️ Utiliser le modèle entraîné pour faire les prédictions correspondantes au jeu de test. \n",
        "\n",
        "➡️ Afficher les performances du modèle. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9T3oT64OOyT2"
      },
      "outputs": [],
      "source": [
        "# correction\n",
        "y_pred_tfidf = classif_model_tfidf.predict(x_test_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33Bovb1we1jG"
      },
      "outputs": [],
      "source": [
        "# correction\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test_news, y_pred_tfidf))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐ Barème : 2 points\n",
        "\n",
        "- utilisation de la méthode `predict` sur les données de test (1 point)\n",
        "- affichaque d'une métrique pertinente telle que l'accuracy ou f1-score (1 point)"
      ],
      "metadata": {
        "id": "jhJFoX7nCo23"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bxvTU3ZOysZ"
      },
      "source": [
        "➡️ Recommencer la partie classification avec SOIT :\n",
        "- une autre technique de vectorisation de votre choix\n",
        "- une étape de pre-processing à appliquer avant de reproduire la même vectorisation. \n",
        "\n",
        "Les jeux d'entraînement et de test doivent rester les mêmes pour que la comparaison soit la plus pertinente possible. Le modèle de classification choisi ne doit pas changer non plus, seule la technique de vectorisation ou l'ajout de l'étape de pre-processing change. \n",
        "\n",
        "➡️ Commenter les résultats obtenus. Tenter d'expliquer la différence de performance s'il y en a une."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awen7_tCPw9s"
      },
      "outputs": [],
      "source": [
        "# correction autre modèle\n",
        "classif_model_bert = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto',probability=True)    \n",
        "\n",
        "classif_model_bert.fit(X_train_bert,y_train_news)\n",
        "y_pred_bert = classif_model_bert.predict(x_test_bert)\n",
        "print(classification_report(y_test_news, y_pred_bert))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# correction pre-processing\n",
        "\n",
        "def clean_text(text):\n",
        "  clean_text = text.replace('\\n','')\n",
        "  clean_text = clean_text.replace('\\t','')\n",
        "  # tri des emails, des stop words, de la ponctuation, lemmatisation, etc... \n",
        "  return clean_text\n",
        "\n",
        "X_train_pre = [clean_text(news) for news in X_train_news]\n",
        "x_test_pre = [clean_text(news) for news in x_test_news]\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_train_pre_tfidf = tfidf_vectorizer.fit_transform(X_train_pre)\n",
        "x_test_pre_tfidf = tfidf_vectorizer.transform(x_test_pre)\n",
        "\n",
        "classif_model_pre_tfidf = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto',probability=True)    \n",
        "classif_model_pre_tfidf.fit(X_train_pre_tfidf,y_train_news)\n",
        "y_pred_pre_tfidf = classif_model_pre_tfidf.predict(x_test_pre_tfidf)\n",
        "print(classification_report(y_test_news, y_pred_pre_tfidf))"
      ],
      "metadata": {
        "id": "0zvz_yzALNUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐ Barème : 5 points\n",
        "\n",
        "- changement de technique de vectorisation : 2 points\n",
        "  - choix d'une technique pertinente (1 point)\n",
        "  - bonne implémentation sur les mêmes données (1 point)\n",
        "- pre-processing sur la même technique de vectorisation : 2 points\n",
        "  - les techniques de pre-processing sont choisies de façon pertinente par rapport aux données (1 point)\n",
        "  - le pre-processing est implémenté proprement avec les librairies adaptées comme nltk, spacy, en utilisant des regex, la fonction replace, etc... (1 point)\n",
        "- nouvelle classification correctement exécutée (1 point)\n",
        "- explication sur la différence de performance (2 points)"
      ],
      "metadata": {
        "id": "j_Twu7WKEDTs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJDXF0FnP36F"
      },
      "source": [
        "## Topic Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4oZJWBeQ4XQ"
      },
      "source": [
        "➡️ Choisir une méthode **non supervisée** permettant de faire du topic modeling. Commenter votre choix.\n",
        "\n",
        "➡️ Implémenter cette méthode et l'exécuter sur les données vectorisées avec une des méthodes précédemment utilisée de votre choix.\n",
        "\n",
        "Le nombre de clusters est fixé à **20**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXH8-bbjP6lo"
      },
      "outputs": [],
      "source": [
        "# correction\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "lda = LatentDirichletAllocation(n_components=20)\n",
        "lda.fit(X_train_tfidf)\n",
        "y_pred_lda = lda.transform(x_test_tfidf)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐ Barème : 3 points\n",
        "\n",
        "- choix de la méthode pertinente comme LDA, LSA, K-means,... (1 point)\n",
        "- bonne implémentation de la méthode (2 points)"
      ],
      "metadata": {
        "id": "XgAtU_yoE62S"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtRQuuJRRKsS"
      },
      "source": [
        "➡️ Afficher les mots représentatifs de chacun des clusters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGRL1KFfRU4I"
      },
      "outputs": [],
      "source": [
        "# correction\n",
        "for index,topic in enumerate(lda.components_):\n",
        "    print(f'10 mots majoritairement représentant le cluster {index} : ')\n",
        "    print([tfidf_vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-10:]])\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐ Barème : 1 point"
      ],
      "metadata": {
        "id": "86l7RetlFI2r"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DteWV5bRVQD"
      },
      "source": [
        "➡️ Utiliser une métrique vous paraissant pertinente pour évaluer les clusters identifiés par rapport aux labels existants des données. \n",
        "\n",
        "➡️ Commenter le score obtenu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10Zh7Zq7SnNB"
      },
      "outputs": [],
      "source": [
        "# correction\n",
        "import numpy as np\n",
        "from sklearn.metrics.cluster import adjusted_rand_score\n",
        "\n",
        "y_pred_clusters = []\n",
        "for pred in y_pred_lda:\n",
        "  y_pred_clusters.append(np.argmax(pred))\n",
        "\n",
        "adjusted_rand_score(y_test_news, y_pred_clusters)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐ Barème : 1 point"
      ],
      "metadata": {
        "id": "V00d2oYUHZwk"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}